{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dfe3521",
   "metadata": {},
   "source": [
    "# Uploading Fine-Tuned Models to the Hugging Face Hub\n",
    "\n",
    "This notebook provides a step-by-step guide to upload your locally fine-tuned sentiment analysis models to the Hugging Face Hub. This is the standard and recommended way to share and store your models.\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "1.  **Hugging Face Account**: Make sure you have a Hugging Face account. If not, create one at [huggingface.co/join](https://huggingface.co/join).\n",
    "2.  **Access Token**: You need a Hugging Face access token with `write` permissions. You can generate one from your settings: [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b4de45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install the necessary library\n",
    "# The huggingface_hub library is essential for interacting with the Hub.\n",
    "!pip install huggingface_hub -q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daab22d8",
   "metadata": {},
   "source": [
    "## Step 2: Log in to the Hugging Face Hub\n",
    "\n",
    "Run the following cell. It will prompt you to enter your access token that you generated from your Hugging Face profile. Paste the token and press Enter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07ce8bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932e8c73d302437e8a11fbd98efde9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a9dbf6",
   "metadata": {},
   "source": [
    "## Step 3: Load Your Fine-Tuned Model and Push to Hub\n",
    "\n",
    "Now, we will load the model and tokenizer from the local directory where it was saved after training. Then, we'll push them to the Hub.\n",
    "\n",
    "**Important**: You need to define two things in the next cell:\n",
    "1.  `local_model_run_dir`: The path to the specific model run you want to upload. I have pre-filled it with the correct path for your best model, `google/muril-base-cased`.\n",
    "2.  `hf_repo_name`: The name you want for your model repository on the Hugging Face Hub. It will be created under your username (e.g., `YourUsername/marathi-sentiment-muril-base`). **Make sure to change this to your desired name.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8de0652a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected run folder: C:\\LLM's_for_SA\\results\\notebook_run\\20250917_142448\n",
      "Loading model and tokenizer from: C:\\LLM's_for_SA\\results\\notebook_run\\20250917_142448\\model\n",
      "Pushing model to Hugging Face Hub repository: AshParmar/XMR-Muril\n",
      "Pushing model to Hugging Face Hub repository: AshParmar/XMR-Muril\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ad908612f9418eacf85f0924efdb8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95143be9dac4884a9d81e27b334ef11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba5edf4b30f42acb87a48a9b1d0cfac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...\\Temp\\tmpn6jfef7d\\model.safetensors:   7%|7         | 67.1MB /  950MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed successfully!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6796f8a50f28410fa1b8c674ccf6be48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ashpa\\miniconda3\\envs\\marx\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ashpa\\.cache\\huggingface\\hub\\models--AshParmar--XMR-Muril. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer pushed successfully!\n",
      "\n",
      "✅ Successfully uploaded model and tokenizer to: https://huggingface.co/AshParmar/XMR-Muril\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Root folder containing timestamped runs (this is the correct base path)\n",
    "runs_root = Path(r\"C:\\LLM's_for_SA\\results\\notebook_run\")\n",
    "\n",
    "# Option A (recommended): Manually set a specific run folder by uncommenting and editing the line below\n",
    "local_model_run_dir = runs_root / \"20250917_142448\"  # <- change to your desired run folder\n",
    "\n",
    "# Option B (fallback): Auto-pick the most recent run that contains a 'model' subfolder\n",
    "try:\n",
    "    local_model_run_dir\n",
    "except NameError:\n",
    "    candidates = [p for p in runs_root.iterdir() if p.is_dir() and (p / \"model\").exists()]\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No run folders with a 'model' subfolder found in: {runs_root}.\\n\"\n",
    "            \"Tip: Set 'local_model_run_dir' manually to one of the timestamp folders.\"\n",
    "        )\n",
    "    local_model_run_dir = max(candidates, key=lambda p: p.stat().st_mtime)\n",
    "\n",
    "print(f\"Selected run folder: {local_model_run_dir}\")\n",
    "\n",
    "# 2) Name for your new repository on the Hugging Face Hub (must be unique under your username/org)\n",
    "hf_repo_name = \"AshParmar/XMR-Muril\"  # IMPORTANT: Change this!\n",
    "\n",
    "# --- SCRIPT ---\n",
    "# Define the path to the final trained model files\n",
    "local_model_path = local_model_run_dir / \"model\"\n",
    "\n",
    "# Check if the model directory exists\n",
    "if not local_model_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Model directory not found at: {local_model_path}.\\n\"\n",
    "        f\"Tip: Update 'local_model_run_dir' to one of the folders inside {runs_root}\"\n",
    "    )\n",
    "\n",
    "print(f\"Loading model and tokenizer from: {local_model_path}\")\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(local_model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_model_path)\n",
    "\n",
    "print(f\"Pushing model to Hugging Face Hub repository: {hf_repo_name}\")\n",
    "\n",
    "# Push the model and tokenizer to the Hub\n",
    "model.push_to_hub(hf_repo_name)\n",
    "print(\"Model pushed successfully!\")\n",
    "\n",
    "tokenizer.push_to_hub(hf_repo_name)\n",
    "print(\"Tokenizer pushed successfully!\")\n",
    "\n",
    "print(f\"\\n✅ Successfully uploaded model and tokenizer to: https://huggingface.co/{hf_repo_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
