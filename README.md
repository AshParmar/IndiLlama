# Marathi Sentiment Analysis: Lexicon + Translation + Balanced Splits

> End-to-end reproducible workflow for Marathi sentiment analysis combining: (1) dataset unification & translation with caching, (2) domain & class balancing, (3) construction of a Marathi SentiWordNet-derived lexicon, and (4) an interpretable lexicon-only baseline ready for extension with transformers / LLMs.

---
## 1. Motivation
Low-resource Indic languages like Marathi lack large high-quality sentiment resources. Pure end-to-end fine-tuning can ignore rich lexical priors embedded in Marathi WordNet / IndoWordNet. This project provides:
* A pipeline to parse & align Marathi WordNet with English WordNet + SentiWordNet for polarity priors.
* A translation + caching framework to obtain English counterparts (supporting lexical scoring & multilingual modeling).
* Strict domain-class balancing (Movie Reviews vs Social Tweets) to avoid domain skew.
* A transparent lexicon-based baseline with coverage diagnostics and error analysis.
* A foundation for hybrid (lexicon + transformer / LLM) approaches (future roadmap).

### üéØ Quick Results Summary
| Method | Dataset | Accuracy | Best F1 | Key Features |
|--------|---------|----------|---------|--------------|
| **Direct Lexicon** | 30K Balanced | **49.7%** | 0.533 | No translation needed |
| **SWN + Translation (Google)** | 30K Balanced | **53.4%** | 0.570 | 100% translation coverage |
| **SWN + Translation (Marian)** | 30K Balanced | **48.2%** | 0.503 | Offline Marian MT pipeline |
| *Random Baseline* | - | *33.3%* | - | *Reference* |

üìä **Dataset**: L3Cube MahaSent (15K Movie Reviews + 15K Social Tweets)  
üîÑ **Reproducible**: Cached translations, balanced splits, deterministic pipeline  
üìà **Improvement**: +16.4pp over random baseline with direct lexicon approach

---
## 2. Core Notebooks & Their Roles
| Notebook | Purpose | Key Outputs |
|----------|---------|-------------|
| `marathi_sentiment_swn_pipeline.ipynb` | Unified pipeline: dataset discovery, cleaning, translation (cached via Google Translate), optional domain-class balancing, SentiWordNet scoring | `output/combined_marathi_dataset.csv`, `translation_cache.json`, balanced splits under `output/combined_dataset/`, scored columns (pos/neg/objective) in merged frame |
| `marathi_sa_lexicon_approach.ipynb` | Lexicon-focused baseline (movie reviews + balanced combined data). Tokenization, lexicon mapping, prediction aggregation, evaluation, word clouds, error analysis | `movie_review_predictions_lexicon.csv` |
| `google_translate.ipynb`, `mariante_translate.ipynb` | Alternative translation experiments feeding lexicon enrichment | Intermediate translated CSV variants |
| `lexi.ipynb`, `lexin.ipynb` | Lexicon exploration / refinement experiments | Variant lexicon CSVs |
| `sentiwordnet_for_words.ipynb` | Builds Marathi ‚Üî English lexicon using SentiWordNet averaging; assigns polarity labels and exports final lexicon | `marathi_word_sentiments.csv` |

---
## 3. Repository Structure (Essentials)
```
MarathiWN_1_3/               # Marathi WordNet distribution (config + database + jars)
scripts/parse_mwn.py         # Parser for synsets, glosses, WordNet alignment
output/                      # Generated artifacts (datasets, metrics, word clouds, predictions)
fonts/                       # Downloaded / bundled Devanagari font (Noto Sans)
marathi_word_sentiments.csv  # Final SentiWordNet-derived Marathi lexicon (produced by scoring notebook)
translation_cache.json       # Persisted translation results (Marathi -> English)
```
Additional CSVs (`marathi_sentiwordnet_google.csv`, `marathi_sentiwordnet_mariante.csv`, `marathi_lexicon_correct_pos.csv`) represent intermediate lexicon variants.

---
## 4. Datasets
### 4.1 L3Cube MahaSent (Movie Reviews + Social Tweets)
* Multiple CSV splits typically: `MahaSent_MR_Train.csv`, `MahaSent_ST_Train.csv`, etc.
* Labels appear as text or numeric variants: {-1, 0, 1} mapped to {negative, neutral, positive}.

### 4.2 Balanced Combined Dataset
Generated by `marathi_sentiment_swn_pipeline.ipynb` using balance modes:
* `strict`: Equal counts per (label, source). Produces `train_strict.csv`, `val_strict.csv`, `test_strict.csv` and/or `balanced_mode_strict.csv`.
* `proportional`: Keep natural merged distribution.
* `none`: No balancing (raw merged after cleaning).

### 4.3 Marathi WordNet (v1.3)
Used for lexical prior construction. Raw data under `MarathiWN_1_3/database/` parsed by `scripts/parse_mwn.py`.

### 4.4 Constructed Marathi SentiWordNet Lexicon
`marathi_word_sentiments.csv` columns (canonical):
* `marathi_word`
* `sentiment_label` (positive | negative | neutral)
* Optionally numeric scores (`pos_score`, `neg_score`, `obj_score`) if computed.

Noise handling & filtering heuristics (regex, bracket stripping, transliteration checks) are applied in earlier experiments.

---
## 5. End-to-End Workflow Overview
1. (Optional) Parse WordNet: `python scripts/parse_mwn.py` ‚Üí intermediate synset file.
2. Generate / refine lexicon variants (translation notebooks) ‚Üí enriched English alignment.
3. Run `marathi_sentiment_swn_pipeline.ipynb`:
   * Discover & load MR + ST datasets.
   * Clean, deduplicate, normalize labels.
   * Translate to English with caching (`translation_cache.json`).
   * (Optional) Apply balance mode (`strict` recommended for domain parity).
   * Score English tokens with SentiWordNet ‚Üí add polarity columns.
   * Save combined & balanced CSVs under `output/`.
4. Run `marathi_sa_lexicon_approach.ipynb`:
   * Load lexicon file (`marathi_word_sentiments.csv`).
   * Load balanced splits (if available) or fall back to combined dataset.
   * Tokenize Devanagari text; map tokens to sentiment values.
   * Aggregate predictions (majority & weighted strategies).
   * Evaluate metrics, create confusion matrix, word clouds, error set.
   * Export predictions to CSV.
5. (Future) Train transformer / hybrid models leveraging lexicon coverage & polarity features.

---
## 6. Installation & Environment
Requirements (Python 3.10+ suggested):
```bash
pip install -r requirements.txt
```
Ensure NLTK corpora (idempotent):
```python
import nltk
for r in ["punkt","wordnet","omw-1.4","sentiwordnet","stopwords"]:
    try:
        nltk.data.find(r)
    except LookupError:
        nltk.download(r)
```

Fonts: The lexicon baseline auto-downloads Noto Sans Devanagari if a suitable system font is missing (stored under `fonts/`).

---
## 7. Translation Caching
`translation_cache.json` stores: `{ "<marathi_text>": { "english": "<translation>", "ok": true } }`.
* Incrementally updated every N new translations (`CACHE_SAVE_INTERVAL`).
* Safe to reuse across sessions; delete if you want a clean re-translate.
* Failed translations recorded with `"ok": false` and optionally an error message.

---
## 8. Lexicon Baseline (Movie Reviews Focus)
Aggregation strategies implemented:
* Majority vote over non-neutral token sentiments (tie ‚Üí neutral).
* Weighted sum (sum(signs); margin threshold for neutrality).

Coverage metric per sentence:
```
lexicon_coverage = matched_tokens_count / (matched_tokens_count + unmatched_tokens_count)
```
Use as a routing signal (e.g., send low-coverage sentences to an ML model).

Idempotency: Updated notebook adds `ensure_review_predictions()` so re-running cells out of order auto-generates missing prediction columns.

### 8.1 Lexicon Builder Notebook (`sentiwordnet_for_words.ipynb`)
This notebook was restored and is now explicitly documented. It constructs the Marathi sentiment lexicon by:
1. Loading a source CSV (e.g., `marathi_sentiwordnet_google.csv`) containing columns such as `marathi_word`, `english_word` (or translation), optional POS / synset IDs.
2. Normalizing English tokens (lowercasing, stripping bracketed metadata, removing non‚Äëalphabetic chars, keeping only the first token if multi-word).
3. Fetching all WordNet synsets for each English lemma and averaging their SentiWordNet (`pos`, `neg`, `obj`) scores (simple first-pass heuristic).
4. Assigning a sentiment label with a small margin (default 0.05) to avoid classifying near-ties as strongly polarized.
5. (Optional) Generating a color-coded word cloud (green = positive, red = negative, grey = neutral) with Devanagari font auto-detection / fallback download.
6. Exporting `marathi_word_sentiments.csv` used by downstream lexicon baseline notebooks.

Label scheme in the restored version may use symbolic labels (`+`, `-`, `neutral`). For consistency with the rest of the pipeline (which expects `positive`, `negative`, `neutral`), map them after loading:
```python
lex = pd.read_csv('marathi_word_sentiments.csv')
symbol_map = {'+':'positive','-':'negative','positive':'positive','negative':'negative'}
lex['sentiment_label'] = lex['sentiment_label'].map(symbol_map).fillna('neutral')
```

If you plan to regenerate the lexicon with multi-synset strategies or lemmatization, consider swapping the simple average for:
* First-sense only (fast, less noise) ‚Äì already partially supported.
* Frequency-weighted average using sense frequency counts (requires additional resources).
* Top-K mean (e.g., mean of first 3 synsets) to reduce outlier influence.

Utility function recommendation: If you frequently probe ad-hoc English word lists, lift the scoring logic into a helper similar to:
```python
def sentiwordnet_for_words(words, aggregate='sum', margin=0.05):
    # returns dict: {'pos':..., 'neg':..., 'obj':..., 'count':..., 'label':..., 'details':[...]}
    ...
```
and reuse it both in the lexicon builder and evaluation notebooks (avoids duplication and keeps classification thresholds centralized).

Quality caveats:
* Averaging across all synsets can dilute polarity; sense disambiguation or restricting to top-1 improves precision at the cost of recall.
* Marathi ‚Üí English translation noise can inject misleading lemmas‚Äîinclude a frequency or confidence filter if available.
* Neutral dominance is expected for words lacking strong polarity; verify distribution to avoid skew.

---
## 9. Command & Data Reference
| Artifact | Produced By | Path |
|----------|-------------|------|
| Combined dataset (legacy) | Pipeline notebook | `output/combined_marathi_dataset.csv` |
| Strict balanced splits | Pipeline notebook (`BALANCE_MODE=strict`) | `output/combined_dataset/train_strict.csv` etc. |
| Lexicon file | Lexicon scoring notebook | `marathi_word_sentiments.csv` |
| Predictions (lexicon baseline) | Lexicon baseline notebook | `movie_review_predictions_lexicon.csv` |
| Translation cache | Pipeline notebook | `translation_cache.json` |
| Word clouds / metrics plots | Both notebooks | `output/` images |

### 9.1 Standalone Balancing Script
For convenience (outside the notebook), a CLI script `output/balance_dataset.py` now provides three balancing modes directly on `combined_marathi_dataset.csv`:

Modes:
* `strict-domain`  ‚Äì Equalize counts for each (label, source) pair.
* `label-only`     ‚Äì Balance only by label (ignores domain proportion).
* `proportional`   ‚Äì No balancing (shuffled copy), useful as a control.

Outputs written alongside the input (or to `--output-dir`):
```
balanced_mode_<mode>.csv
train_<mode>.csv
val_<mode>.csv
test_<mode>.csv  (splits only for strict-domain / label-only)
```

Example usage (PowerShell / CMD):
```bash
python output/balance_dataset.py --input output/combined_marathi_dataset.csv --mode strict-domain --seed 42
python output/balance_dataset.py --input output/combined_marathi_dataset.csv --mode label-only --seed 42
```

To point results to a custom directory:
```bash
python output/balance_dataset.py --input output/combined_marathi_dataset.csv --mode strict-domain --output-dir output/balanced_custom
```

Integration tip: The lexicon baseline notebook will automatically detect strict split files if placed in `output/` with the expected naming (`train_strict_domain.csv`, etc.). Rename or symlink as needed if you adopt a different folder.

---
## 10. Quick Start (Minimal Reproduction)
```bash
# 1. Install
pip install -r requirements.txt

# 2. (Optional) Prepare NLTK data
python -c "import nltk; [nltk.download(p) for p in ['punkt','wordnet','omw-1.4','sentiwordnet','stopwords']]"

# 3. Open Jupyter / VSCode notebooks and run:
#    a) marathi_sentiment_swn_pipeline.ipynb (choose BALANCE_MODE)
#    b) marathi_sa_lexicon_approach.ipynb

# 4. Inspect outputs
python - <<'PY'
import pandas as pd
pred = pd.read_csv('movie_review_predictions_lexicon.csv')
print('Rows:', len(pred), 'Mean coverage:', pred.lexicon_coverage.mean())
print(pred.head())
PY
```

---
## 11. Evaluation Results & Model Performance

### 11.1 Dataset Summary
| Dataset | Type | Train | Validation | Test | Total | Source |
|---------|------|-------|------------|------|-------|--------|
| **L3Cube MahaSent MR** | Movie Reviews | 12,003 | 1,501 | 1,501 | 15,005 | L3Cube Research |
| **L3Cube MahaSent MS** | Social Tweets | 12,008 | 1,503 | 1,502 | 15,013 | L3Cube Research |
| **Combined Balanced** | Mixed Domain | - | - | - | 30,000 | Generated (strict mode) |

**Label Distribution (Balanced Dataset):**
- Positive: 10,000 samples (33.3%)
- Negative: 10,000 samples (33.3%)  
- Neutral: 10,000 samples (33.3%)

### 11.2 Model Approaches & Performance

| Approach | Method | Accuracy | Precision | Recall | F1-Score | Coverage | Translation |
|----------|--------|----------|-----------|--------|----------|----------|-------------|
| **SentiWordNet + Translation (Google)** | Marathi‚ÜíEnglish + SWN scoring | **53.39%** | 0.538 | 0.534 | 0.533 | ~100% | Google Translate (deep_translator) |
| **SentiWordNet + Translation (Marian)** | Marathi‚ÜíEnglish + SWN scoring | **48.20%** | 0.485 | 0.482 | 0.481 | ~100% | Helsinki-NLP Marian |
| **Direct Lexicon Mapping** | Marathi lexicon lookup | **49.72%** | 0.524 | 0.497 | 0.493 | Variable | No translation |

### 11.3 Detailed Performance Breakdown

#### 11.3.1 SentiWordNet + Translation Approach (Google Translate)
**Overall Performance:**
- Accuracy: 53.39%
- Total Samples: 30,000
- Translation Success Rate: 100%

**Per-Class Performance:**
| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| Negative | 0.593 | 0.488 | 0.536 | 10,000 |
| Neutral | 0.485 | 0.505 | 0.495 | 10,000 |
| Positive | 0.536 | 0.609 | 0.570 | 10,000 |

**Method Details:**
- Artifacts: See `output/metrics_summary.json` for the full metrics dump and `output/confusion_matrix.png` for the confusion matrix image.
- Notebook: `marathi_sentiment_swn_pipeline.ipynb` (sections on translation and evaluation)

- Translation: Google Translate via deep_translator (Marathi ‚Üí English) with caching
- POS Tagging: NLTK POS tagger on English translations
- Sentiment Scoring: SentiWordNet 3.0 with synset score aggregation (pos/neg/obj)
- Decision Threshold: Margin-based (positive_score - negative_score > 0.05)
- Text Processing: Lemmatization, stopword removal, translation caching

#### 11.3.2 SentiWordNet + Translation Approach (Marian MT)
**Overall Performance:**
- Accuracy: 48.20%
- Total Samples: 30,000
- Translation Success Rate: ~100%

**Per-Class Performance:**
| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| Negative | 0.529 | 0.455 | 0.490 | 10,000 |
| Neutral | 0.457 | 0.446 | 0.451 | 10,000 |
| Positive | 0.468 | 0.544 | 0.503 | 10,000 |

**Method Details:**
- Translation: Helsinki-NLP Marian MT model (mar‚Üíen)
- POS Tagging: NLTK POS tagger on English translations
- Sentiment Scoring: SentiWordNet 3.0 first-sense lookup
- Decision Threshold: Margin-based (positive_score - negative_score > 0.05)
- Text Processing: Lemmatization, stopword removal, translation caching

Artifacts for this run may be saved under `output/` as well (e.g., metrics/figures); if running both pipelines, consider suffixing or subfolders to avoid overwrite.

#### 11.3.3 Direct Lexicon Mapping Approach  
**Overall Performance:**
- Accuracy: 49.72%
- Total Samples: 30,000
- Lexicon Coverage: Variable (depends on vocabulary overlap)

**Per-Class Performance:**
| Class | Precision | Recall | F1-Score | Support |
|-------|-----------|--------|----------|---------|
| Negative | 0.574 | 0.378 | 0.456 | 10,000 |
| Neutral | 0.463 | 0.629 | 0.533 | 10,000 |
| Positive | 0.481 | 0.484 | 0.482 | 10,000 |

**Method Details:**
- Lexicon: Marathi-English aligned SentiWordNet-derived lexicon
- Tokenization: Devanagari text tokenization
- Aggregation: Majority voting with weighted sum fallback
- Coverage: Direct word matching (no fuzzy matching or stemming)

### 11.4 Key Findings

#### 11.4.1 Strengths
‚úÖ **Translation Robustness**: 100% translation success rate with caching  
‚úÖ **Domain Balance**: Strict domain-class balancing ensures fair evaluation  
‚úÖ **Lexicon Coverage**: Direct lexicon approach shows competitive performance  
‚úÖ **Reproducibility**: Deterministic pipeline with cached intermediate results  

#### 11.4.2 Limitations
‚ùå **Overall Accuracy**: Lexicon-only remains ~50%; SWN+Translate varies by MT (‚âà48‚Äì53%)  
‚ùå **Translation Noise**: Translation artifacts (esp. Marian vs Google) can affect scoring  
‚ùå **Lexicon Coverage**: Limited vocabulary coverage in direct mapping approach  
‚ùå **Class Imbalance**: Recall varies significantly across sentiment classes  

#### 11.4.3 Error Analysis
- **Neutral Classification**: Both models tend to over-predict neutral sentiment
- **Translation Quality**: Domain-specific terms (slang, colloquialisms) lose sentiment nuance
- **Lexicon Gaps**: Many Marathi words lack direct sentiment mappings
- **Context Ignorance**: Bag-of-words approaches miss contextual sentiment

### 11.5 Comparison with Baselines

| Metric | Random Baseline | Majority Class | SWN+Translation (Google) | SWN+Translation (Marian) | Direct Lexicon |
|--------|----------------|----------------|---------------------------|-------------------------|----------------|
| Accuracy | 33.3% | 33.3% | **53.4%** | 48.2% | **49.7%** |
| Improvement | - | - | +20.1pp | +14.9pp | +16.4pp |

### 11.6 Output Files & Artifacts

**Generated Files:**
- `output/metrics_summary.json`: Complete evaluation metrics
- `output/confusion_matrix.png`: Visualization of prediction errors  
- `output/wordcloud_*_english.png`: English sentiment wordclouds
- `output/wordcloud_*_marathi.png`: Marathi sentiment wordclouds
- `output/combined_marathi_dataset.csv`: Unified and cleaned dataset
- `output/merged_sentiment_results.csv`: Predictions with scores
- `translation_cache.json`: Cached translations (30K+ entries)

---
## 12. Troubleshooting
| Symptom | Likely Cause | Fix |
|---------|-------------|-----|
| KeyError: prediction columns missing | Ran sample display before prediction cell | Re-run Section 7 in lexicon notebook (now idempotent) |
| Coverage extremely low | Lexicon missing many words | Expand lexicon, enable fuzzy matching, add morphological normalization |
| All predictions neutral | Margin too high or low polarity scores | Lower weighted sum margin; verify sentiment_label mapping |
| Word clouds blank | Font missing or no Devanagari tokens | Ensure `fonts/NotoSansDevanagari-Regular.ttf` downloaded, check CSV encoding |
| Balanced split files not found | Pipeline not yet run with strict mode | Run pipeline notebook, ensure `BALANCE_MODE='strict'` |
| Translation rate limits | Too many rapid API calls | Increase backoff, reuse `translation_cache.json` |

---
## 13. Roadmap (Execution-Oriented)
1. POS & sense disambiguation for lexicon scoring.
2. Negation + intensifier handling (Marathi-specific list & window rules).
3. Lexicon feature extractor module (Python package) + unit tests.
4. Classical ML baselines (TF-IDF + lexicon features) script.
5. Transformer fine-tuning (IndicBERT / XLM-R) with feature concatenation.
6. Prompt & soft-prefix lexical hint experiments.
7. QLoRA LLM adaptation with / without lexical hints.
8. Ablation + statistical significance testing.
9. Error clustering & lexicon refinement loop.
10. Packaging & CLI for batch scoring.
11. Extend to additional Indic languages (scalable design).

---
## 14. Potential Enhancements
* Morphological normalization / lightweight stemmer.
* Phonetic / edit-distance fuzzy matching to raise coverage.
* Semi-supervised label propagation using lexicon-derived weak labels.
* Active learning sampling by low coverage + high disagreement.
* Weighted multisynset aggregation (sense frequency weighting).

---
## 15. Citation & Licensing
Please cite the original resources:
* L3Cube MahaSent dataset (movie reviews & social tweets).
* Marathi WordNet / IndoWordNet.
* SentiWordNet 3.0.
* Any pretrained model checkpoints used (IndicBERT, XLM-R, etc.).

BibTeX entries to be added (placeholder).

---
## 16. Quick Insight Snippet (Python)
```python
import pandas as pd
lex = pd.read_csv('marathi_word_sentiments.csv')
print('Lexicon size:', len(lex))
print(lex.head())
```

---
## 17. Disclaimer
The lexicon and derived scores are experimental; translation and alignment noise may affect polarity accuracy. Validate before production or sensitive use cases.

---
Feedback, issues, or feature requests are welcome. Contributions to extend the pipeline or add evaluation scripts for transformer baselines are encouraged.
